{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unt7r3-fKXW4",
        "tags": []
      },
      "source": [
        "# Introduction\n",
        "\n",
        "## **Project: Sentiment Analysis on Amazon Product Reviews**\n",
        "\n",
        "With the rise of e-commerce, online product reviews have become crucial for consumers.\n",
        "\n",
        "Analyzing vast volumes of reviews manually is impractical. Supervised learning models can streamline sentiment analysis on large-scale datasets.\n",
        "\n",
        "Our **study focuses on categorizing feedback as positive or negative and building an efficient sentiment analysis model.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DTZLssIPKllY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "FIRST_NAME = \"Muthu\"\n",
        "LAST_NAME = \"Selvam\"\n",
        "STUDENT_ID = \"801276057\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WolzBH3J50V",
        "outputId": "68ea9acf-36bb-4500-e7d4-9e504570ecbe",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5U4TbgPJ4cI",
        "outputId": "25330a44-2472-4043-8403-1f2d1acc6145",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from contractions import contractions_dict\n",
        "from string import punctuation\n",
        "import warnings\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAhkKHV2J4cK"
      },
      "source": [
        "## Create Amazon Customer Reviews DataFrame from JSON objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "UR1eB6pZJ4cK",
        "outputId": "366ce9f5-ec48-4f32-c800-0ad52f4d5118",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "Compressed file ended before the end-of-stream marker was reached",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-623acc187a40>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amazon_product_reviews.json.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-623acc187a40>\u001b[0m in \u001b[0;36mgetDF\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-623acc187a40>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[1;32m    508\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('amazon_product_reviews.json.gz')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luKOMhomJ4cL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset = ['reviewText','summary'])\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0qnjyI0J4cL",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(df['overall'].value_counts())\n",
        "df['overall'].value_counts(normalize=True) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6xsDWZ3J4cM"
      },
      "source": [
        "## Separate positive and negative reviews for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5dOSO44J4cM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_negative_reviews = df[df['overall']<3].iloc[:50000]\n",
        "df_positive_reviews = df[df['overall']>3].iloc[:50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxhMrZJFJ4cM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_new = df.iloc[:100]\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPJ0otFjQrcg",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# @title overall\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "df_new['overall'].plot(kind='line', figsize=(8, 4), title='overall')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX76qwn5QfeA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# @title overall vs unixReviewTime\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "df_new.plot(kind='scatter', x='overall', y='unixReviewTime', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEjBMtZcJ4cM"
      },
      "source": [
        "## Review Text PreProcssing Function Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_al1m90J4cM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def expand_contractions(text, contractions_dict):\n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
        "                                      flags=re.IGNORECASE | re.DOTALL)\n",
        "\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contractions_dict.get(match) \\\n",
        "            if contractions_dict.get(match) \\\n",
        "            else contractions_dict.get(match.lower())\n",
        "        expanded_contraction = expanded_contraction\n",
        "        return expanded_contraction\n",
        "\n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "\n",
        "def strip_punctuation(s):\n",
        "    return ''.join(c for c in s if c not in punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESbAbCjxJ4cN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "def cleanme(txt):\n",
        "    sent = txt.lower()\n",
        "    sent_expanded_contractions = expand_contractions(sent,contractions_dict)\n",
        "    sent_expanded_contractions = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', sent_expanded_contractions)\n",
        "    sent_without_punct = strip_punctuation(sent_expanded_contractions)\n",
        "    sent_without_digits=re.sub('[0-9]+', '', sent_without_punct)\n",
        "\n",
        "    TOKENIZER = RegexpTokenizer('(?u)\\W+|\\$[\\d\\.]+|\\S+')\n",
        "    wrds = word_tokenize(sent_without_digits)\n",
        "    to_remove = ['no', 'not']\n",
        "    new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
        "    clwrds = [w for w in wrds if not w in new_stopwords]\n",
        "    ln = len(clwrds)\n",
        "    if ln>0:\n",
        "        pos = pd.DataFrame(pos_tag(wrds))\n",
        "        pos = (\" \".join(list(pos[pos[1].str.contains(\"JJ\")].iloc[:,0]))).split(\" \")\n",
        "        l2 = [\"i\",\"you\",\"me\"]\n",
        "        pos = [x for x in pos if x not in l2]\n",
        "    else:\n",
        "        pos = [\"\"]\n",
        "    rt = [ln, \" \".join(clwrds), \" \".join(pos)]\n",
        "    return(rt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKMEiNhuJ4cN"
      },
      "source": [
        "## Create Negative Reviews WordCloud\n",
        "\n",
        "**This will take take time to load all the dataset. Please wait.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY9mWZm9J4cN",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "tmp = list()\n",
        "num_rows = min(50000, len(df_negative_reviews))\n",
        "for i in range(num_rows):\n",
        "    tmp.append(cleanme(df_negative_reviews.iloc[i,:]['reviewText']))\n",
        "\n",
        "tmp = pd.DataFrame(tmp)\n",
        "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
        "\n",
        "df_negative_reviews_new = df_negative_reviews.reset_index()\n",
        "df_negative_reviews_new = pd.concat([df_negative_reviews_new,tmp], axis=1)\n",
        "df_negative_reviews_new = df_negative_reviews_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
        "df_negative_reviews_new.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXLOz25UrrfG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# @title reviewlen\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "df_negative_reviews_new['reviewlen'].plot(kind='line', figsize=(8, 4), title='reviewlen')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKlAZCOiJ4cN",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "\n",
        "txt = df_negative_reviews_new.cleanrev.str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
        "words = nltk.tokenize.word_tokenize(txt)\n",
        "lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
        "bgs = nltk.trigrams(lemmatized_word)\n",
        "\n",
        "#compute frequency distribution for all the bigrams in the text\n",
        "fdist = nltk.FreqDist(bgs)\n",
        "fdist.most_common(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng7_HzE2J4cN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "d = {}\n",
        "for key, value in fdist.items() :\n",
        "    d[\"_\".join(key)] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFomrD4bJ4cN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "WC_height = 200\n",
        "WC_width = 400\n",
        "WC_max_words = 50\n",
        "wordcloud = WordCloud(max_words=WC_max_words, height=WC_height, width=WC_width, background_color=\"white\")\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "wordcloud.to_file(\"WordCloud_Bigrams_frequent_words.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj9iQW03J4cN"
      },
      "source": [
        "## Create Positive Reviews WordCloud\n",
        "\n",
        "**This will take take time to load all the dataset. Please wait.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKOcJtVBJ4cN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tmp = list()\n",
        "for i in range(50000):\n",
        "    tmp.append(cleanme(df_positive_reviews.iloc[i,:]['reviewText']))\n",
        "tmp = pd.DataFrame(tmp)\n",
        "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
        "\n",
        "(tmp.head())\n",
        "\n",
        "\n",
        "df_positive_reviews_new = df_positive_reviews.reset_index()\n",
        "df_positive_reviews_new = pd.concat([df_positive_reviews_new,tmp], axis=1)\n",
        "df_positive_reviews_new = df_positive_reviews_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
        "df_positive_reviews_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1VjTaiSJ4cN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "snowball_stemmer = SnowballStemmer('english')\n",
        "\n",
        "txt = df_positive_reviews_new.cleanrev.str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
        "words = nltk.tokenize.word_tokenize(txt)\n",
        "lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "bgs = nltk.trigrams(lemmatized_word)\n",
        "\n",
        "#compute frequency distribution for all the bigrams in the text\n",
        "fdist = nltk.FreqDist(bgs)\n",
        "fdist.most_common(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hS-HvlBJ4cO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "d = {}\n",
        "for key, value in fdist.items() :\n",
        "    d[\"_\".join(key)] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNS42KN0J4cO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "WC_height = 200\n",
        "WC_width = 400\n",
        "WC_max_words = 50\n",
        "wordcloud = WordCloud(max_words=WC_max_words, height=WC_height, width=WC_width, background_color=\"white\")\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "wordcloud.to_file(\"WordCloud_Positive_Reviews.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4W7Fk13J4cO"
      },
      "source": [
        "## PreProcess 50,000 reviews to be used to build classification models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yELfzZ1STr9t"
      },
      "source": [
        "**This will take take time to load all the dataset. Please wait.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbv8o3OWJ4cO"
      },
      "outputs": [],
      "source": [
        "df_new = df.iloc[:50000]\n",
        "\n",
        "\n",
        "tmp = list()\n",
        "for i in range(50000):\n",
        "    tmp.append(cleanme(df_new.iloc[i,:]['reviewText']))\n",
        "tmp = pd.DataFrame(tmp)\n",
        "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
        "\n",
        "(tmp.head())\n",
        "\n",
        "\n",
        "df_new = df_new.reset_index()\n",
        "df_new = pd.concat([df_new,tmp], axis=1)\n",
        "df_new = df_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbkMe7SqJ4cO"
      },
      "outputs": [],
      "source": [
        "df_new.columns = ['overall_rating','reviewText','summary','cleanReviewLength', 'cleanReview', 'adjectives']\n",
        "df_new.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-nMuOrmJ4cO"
      },
      "source": [
        "## Calculate Polarity of Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkVdnq3uJ4cO"
      },
      "outputs": [],
      "source": [
        "!pip install textblob\n",
        "\n",
        "from textblob import TextBlob, Word\n",
        "def detect_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "df_new['polarity'] = df_new.reviewText.apply(detect_polarity)\n",
        "df_new[1:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvw3CP9kJ4cO"
      },
      "source": [
        "## Naive Bayes Multi-Class Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9X5Wqz5J4cO"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "tfidf = TfidfVectorizer(sublinear_tf=False, max_features = 10000, min_df=5,max_df=0.60,ngram_range= (1,2))\n",
        "\n",
        "review_df = pd.concat([\n",
        "    df_new[df_new['overall_rating']==1.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==2.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==3.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==4.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==5.0].sample(n=10000, replace=True)\n",
        "])\n",
        "\n",
        "review_df = review_df[review_df['cleanReviewLength']<50]\n",
        "review_df = review_df[['cleanReview','overall_rating']]\n",
        "train, test = train_test_split(review_df, test_size=0.2)\n",
        "\n",
        "train['overall_rating'].hist();\n",
        "test['overall_rating'].hist();\n",
        "\n",
        "train = pd.get_dummies(train, columns = ['overall_rating'])\n",
        "train.head()\n",
        "\n",
        "test = pd.get_dummies(test, columns = ['overall_rating'])\n",
        "test.head()\n",
        "\n",
        "train.shape, test.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ET4GYuDJ4cO"
      },
      "outputs": [],
      "source": [
        "class NBFeatures(BaseEstimator):\n",
        "    '''Class implementation of Jeremy Howards NB Linear model'''\n",
        "    def __init__(self, alpha):\n",
        "        # Smoothing Parameter: always going to be one for my use\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def preprocess_x(self, x, r):\n",
        "        return x.multiply(r)\n",
        "\n",
        "    # calculate probabilities\n",
        "    def pr(self, x, y_i, y):\n",
        "        p = x[y == y_i].sum(0)\n",
        "        return (p + self.alpha)/((y==y_i).sum()+self.alpha)\n",
        "\n",
        "    # calculate the log ratio and represent as sparse matrix\n",
        "    # ie fit the nb model\n",
        "    def fit(self, x, y = None):\n",
        "        self._r = sparse.csr_matrix(np.log(self.pr(x, 1, y) /self.pr(x, 0, y)))\n",
        "        return self\n",
        "\n",
        "    # apply the nb fit to original features x\n",
        "    def transform(self, x):\n",
        "        x_nb = self.preprocess_x(x, self._r)\n",
        "        return x_nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyKZx1kAJ4cO"
      },
      "outputs": [],
      "source": [
        "# Create pipeline using sklearn pipeline:\n",
        "    # I basically create my tfidf features which are fed to my NB model\n",
        "    # for probability calculations. Then those are fed as input to my\n",
        "    # logistic regression model.\n",
        "lr = LogisticRegression()\n",
        "nb = NBFeatures(1)\n",
        "p = Pipeline([\n",
        "    ('tfidf', tfidf),\n",
        "    ('nb', nb),\n",
        "    ('lr', lr)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bENYHULdJ4cP"
      },
      "outputs": [],
      "source": [
        "class_names = ['overall_rating_1.0', 'overall_rating_2.0','overall_rating_3.0','overall_rating_4.0','overall_rating_5.0']\n",
        "scores = []\n",
        "preds = np.zeros((len(test), len(class_names)))\n",
        "for i, class_name in enumerate(class_names):\n",
        "    train_target = train[class_name]\n",
        "    cv_score = np.mean(cross_val_score(estimator = p, X = train['cleanReview'].values,\n",
        "                                      y = train_target, cv = 3, scoring = 'accuracy'))\n",
        "    scores.append(cv_score)\n",
        "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
        "    p.fit(train['cleanReview'].values, train_target)\n",
        "    preds[:,i] = p.predict_proba(test['cleanReview'].values)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eKwii_UJ4cP"
      },
      "outputs": [],
      "source": [
        "t = metrics.classification_report(np.argmax(test[class_names].values, axis = 1),np.argmax(preds, axis = 1))\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqG1KZeKJ4cP"
      },
      "source": [
        "## Some Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NDOxVPgJ4cP"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "print(df_new['overall_rating'].value_counts())\n",
        "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
        "sns.distplot(\n",
        "    (df_new['overall_rating']), norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
        ").set(xlabel='Overall Rating', ylabel='Count');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rH0Zj24ZJ4cP"
      },
      "outputs": [],
      "source": [
        "df_res = df_new[df_new['cleanReviewLength']>0]\n",
        "print(df_res.groupby('overall_rating', as_index=False)['cleanReviewLength'].mean())\n",
        "print(df_res.groupby('overall_rating', as_index=False)['polarity'].mean())\n",
        "\n",
        "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
        "sns.distplot(\n",
        "    (df_res['cleanReviewLength']), norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
        ").set(xlabel='Review Length', ylabel='Count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuoFdcnyJ4cP"
      },
      "source": [
        "## Some Other Multi-Class Classifier Models which also takes into account Review Length and Polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByKbWmJmJ4cP"
      },
      "outputs": [],
      "source": [
        "df_res = pd.concat([\n",
        "    df_new[df_new['overall_rating']==1.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==2.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==3.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==4.0].sample(n=10000, replace=True),\n",
        "    df_new[df_new['overall_rating']==5.0].sample(n=10000, replace=True)\n",
        "])\n",
        "df_res = df_res[df_res['cleanReviewLength'] < 50]\n",
        "df_res['overall_rating'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYhliQKHJ4cQ"
      },
      "outputs": [],
      "source": [
        "df_100 = df_res.copy()\n",
        "\n",
        "v = TfidfVectorizer(max_features=10000, min_df=5, max_df=0.60)\n",
        "x = v.fit_transform(df_100['cleanReview'])\n",
        "\n",
        "df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names_out())\n",
        "df_100 = df_100.drop('cleanReview', axis=1)\n",
        "\n",
        "df_100.reset_index(drop=True, inplace=True)\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "res = pd.concat([df_100, df1], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KhWrC0rJ4cQ"
      },
      "outputs": [],
      "source": [
        "res1 = res[res.columns.difference(['reviewText','summary', 'adjectives', 'overall_rating'])]\n",
        "normalized_res1 = res1\n",
        "normalized_res1['cleanReviewLength']= (normalized_res1['cleanReviewLength']-normalized_res1['cleanReviewLength'].min())/(normalized_res1['cleanReviewLength'].max()-normalized_res1['cleanReviewLength'].min())\n",
        "normalized_res1['polarity']= (normalized_res1['polarity']-normalized_res1['polarity'].min())/(normalized_res1['polarity'].max()-normalized_res1['polarity'].min())\n",
        "y = res['overall_rating'].values.reshape(-1,1)\n",
        "\n",
        "res1.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjipiMECJ4cQ"
      },
      "source": [
        "## Logistic Regression Classifier and ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxcXNKxnJ4cQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_res1, y, test_size=0.2, random_state= 51)\n",
        "lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train,y_train)\n",
        "\n",
        "print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, lr.predict(X_train)))\n",
        "print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, lr.predict(X_test)))\n",
        "print (\"Area under ROC curve:: \",multiclass_roc_auc_score(y_test,lr.predict(X_test)))\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, lr.predict(X_test))\n",
        "\n",
        "\n",
        "class_names=[1,2,3,4,5] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "ax.xaxis.set_ticklabels(class_names)\n",
        "ax.yaxis.set_ticklabels(class_names)\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crAo5hW2J4cQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "y = label_binarize(y, classes=[1,2,3,4,5])\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "X_train, X_test, y_train, y_test =train_test_split(normalized_res1, y, test_size=0.2, random_state=51)\n",
        "\n",
        "# classifier\n",
        "clf = OneVsRestClassifier(linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg'))\n",
        "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
        "\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "colors = ['blue', 'red', 'green', 'yellow', 'violet']\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i+1, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for multi-class data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l7n20CrJ4cQ"
      },
      "source": [
        "## SVM Linear Classifier and ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHMWbycIJ4cR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming y_train and y_test are one-hot encoded\n",
        "# Convert them to 1D arrays by selecting the index of the maximum value\n",
        "y_train_1d = np.argmax(y_train, axis=1)\n",
        "y_test_1d = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Check the shape of normalized_res1 and y_train_1d\n",
        "print(\"Shape of normalized_res1:\", normalized_res1.shape)\n",
        "print(\"Shape of y_train_1d:\", y_train_1d.shape)\n",
        "\n",
        "# Check if the number of samples in y_train_1d is less than the number of samples in normalized_res1\n",
        "if y_train_1d.shape[0] < normalized_res1.shape[0]:\n",
        "    # Trim normalized_res1 to match the number of samples in y_train_1d\n",
        "    normalized_res1_trimmed = normalized_res1[:y_train_1d.shape[0]]\n",
        "    print(\"Shape of trimmed normalized_res1:\", normalized_res1_trimmed.shape)\n",
        "\n",
        "    # Use the trimmed normalized_res1 for training\n",
        "    X_train, X_test, y_train_1d, y_test_1d = train_test_split(normalized_res1_trimmed, y_train_1d, test_size=0.2, random_state=51)\n",
        "else:\n",
        "    # Use the original normalized_res1 and y_train_1d for training\n",
        "    X_train, X_test, y_train_1d, y_test_1d = train_test_split(normalized_res1, y_train_1d, test_size=0.2, random_state=51)\n",
        "\n",
        "# Train LinearSVC model\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train, y_train_1d)\n",
        "\n",
        "# Evaluate model performance\n",
        "train_accuracy = metrics.accuracy_score(y_train_1d, svm.predict(X_train))\n",
        "test_accuracy = metrics.accuracy_score(y_test_1d, svm.predict(X_test))\n",
        "print(\"Multinomial SVM Train Accuracy:\", train_accuracy)\n",
        "print(\"Multinomial SVM Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Calculate and display confusion matrix\n",
        "cnf_matrix = metrics.confusion_matrix(y_test_1d, svm.predict(X_test))\n",
        "class_names = np.unique(y_test_1d)  # Use unique classes from the test set\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xticks(ticks=np.arange(len(class_names)) + 0.5, labels=class_names)\n",
        "plt.yticks(ticks=np.arange(len(class_names)) + 0.5, labels=class_names)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzXcGkCAJ4cR",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import datasets\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import label_binarize\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "y = label_binarize(y, classes=[1,2,3,4,5])\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "X_train, X_test, y_train, y_test =train_test_split(normalized_res1, y, test_size=0.2, random_state=51)\n",
        "\n",
        "# classifier\n",
        "clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
        "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
        "\n",
        "\n",
        "#Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "colors = ['blue', 'red', 'green', 'yellow', 'violet']\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i+1, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for multi-class data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMm8qeFpJ4cR"
      },
      "source": [
        "## Multinomial Naive Bayes Multi-Class Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQsLYzBlJ4cR",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_res['cleanReview'], df_res['overall_rating'], random_state = 51)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
        "print (\"Multinomial Naive Bayes Train Accuracy :: \", metrics.accuracy_score(y_train, clf.predict(X_train_tfidf)))\n",
        "print (\"Multinomial Naive Bayes Accuracy :: \", metrics.accuracy_score(y_test, clf.predict(count_vect.transform(X_test))))\n",
        "print (\"Area under ROC curve:: \",multiclass_roc_auc_score(y_test,clf.predict(count_vect.transform(X_test))))\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, clf.predict(count_vect.transform(X_test)))\n",
        "cnf_matrix\n",
        "\n",
        "class_names=[1,2,3,4,5] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "# create heatmap\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "ax.xaxis.set_ticklabels(class_names)\n",
        "ax.yaxis.set_ticklabels(class_names)\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix', y=1.1)\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8j3tu5RJ4cR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "y = label_binarize(y, classes=[1,2,3,4,5])\n",
        "n_classes = 5\n",
        "\n",
        "# shuffle and split training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_res['cleanReview'], y, random_state = 51)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "# classifier\n",
        "clf = OneVsRestClassifier(MultinomialNB())\n",
        "y_score = clf.fit(X_train_tfidf, y_train).predict_proba(count_vect.transform(X_test))\n",
        "\n",
        "\n",
        "#Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_score[:,i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "colors = ['blue', 'red', 'green', 'yellow', 'violet']\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i+1, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for multi-class data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSqu1zw7SnM2"
      },
      "source": [
        "# Accuracy of Result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Classifier:** Achieved a training accuracy of around 73.87% and a test accuracy of around 63.39%. The area under the ROC curve is approximately 0.77.\n",
        "\n",
        "**SVM Linear Classifier:** Achieved a training accuracy of around 50.19% and a test accuracy of around 19.95%. This model seems to perform poorly compared to Logistic Regression.\n",
        "\n",
        "**Naive Bayes Multi-Class Classifier:** Achieved a training accuracy of around 73.15% and a test accuracy of around 60.34%. The area under the ROC curve is approximately 0.75.\n",
        "\n",
        "**Automated Data Labeling using PCA:** Utilized PCA to reduce the dimensionality of TF-IDF vectorized review data, followed by KMeans clustering to assign cluster labels as automated data labels for sentiment analysis.\n",
        "\n",
        "Overall, Logistic Regression and Naive Bayes classifiers performed relatively better compared to SVM. It's interesting to see the use of PCA for automated data labeling, which can be a useful technique for exploratory analysis and understanding the data distribution."
      ],
      "metadata": {
        "id": "jJFqN-Zd2lvb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_QYmV45Y598"
      },
      "source": [
        "# Automated data labelling using PCA and generalizing the approach\n",
        "\n",
        "Automating data labeling using PCA (Principal Component Analysis) for sentiment analysis involves reducing the dimensionality of the data and then using clustering algorithms to group similar data points together.\n",
        "\n",
        "In this code:\n",
        "\n",
        "\n",
        "1.   We perform PCA to reduce the dimensionality of the TF-IDF vectorized review data.\n",
        "\n",
        "2.   We then scale the data and apply PCA to obtain 2 principal components for visualization.\n",
        "\n",
        "3.   We visualize the PCA components to understand the data distribution.\n",
        "\n",
        "4.   We use the Elbow Method to determine the optimal number of clusters for KMeans clustering.\n",
        "\n",
        "5.   We apply KMeans clustering with the optimal number of clusters.\n",
        "\n",
        "6.   We assign cluster labels to the data.\n",
        "\n",
        "7.   We visualize the clustered data to see how the data points are grouped.\n",
        "\n",
        "8.   We label the clusters based on the interpretation of reviews within each cluster.\n",
        "\n",
        "8.   Finally, we can use these cluster labels as automated data labels for sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52agZUj87NhE"
      },
      "outputs": [],
      "source": [
        "!pip show scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster._kmeans import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df_negative_reviews_new contains the preprocessed negative reviews data\n",
        "# Perform PCA to reduce dimensionality\n",
        "X = df_negative_reviews_new['cleanrev']\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.toarray())\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Visualize PCA components\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA Components')\n",
        "plt.show()\n",
        "\n",
        "# Determine optimal number of clusters using Elbow Method\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(X_pca)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 11), wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "# Based on the elbow method, select optimal number of clusters\n",
        "optimal_clusters = 3  # Adjust as needed\n",
        "\n",
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "cluster_labels = kmeans.fit_predict(X_pca)\n",
        "\n",
        "# Assign cluster labels to data\n",
        "df_negative_reviews_new['cluster_label'] = cluster_labels\n",
        "\n",
        "# Visualize clustered data\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(optimal_clusters):\n",
        "    plt.scatter(X_pca[cluster_labels == i, 0], X_pca[cluster_labels == i, 1], label=f'Cluster {i}', alpha=0.5)\n",
        "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', label='Centroids')\n",
        "plt.title('Clustered Data')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2jQrRiFSsRG"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Based on the analysis conducted for sentiment analysis using various classifiers and automated data labeling techniques:\n",
        "\n",
        "**Classifier Performance:**\n",
        "*   Logistic Regression and Naive Bayes classifiers outperformed the SVM classifier in terms of accuracy and area under the ROC curve.\n",
        "\n",
        "*   Logistic Regression achieved the highest accuracy among the tested classifiers, followed closely by Naive Bayes.\n",
        "\n",
        "\n",
        "**Model Evaluation:**\n",
        "*   The evaluation metrics, including accuracy, precision, recall, and F1-score, provide insights into the performance of each classifier across different sentiment classes.\n",
        "\n",
        "*   Logistic Regression and Naive Bayes classifiers demonstrated relatively balanced performance across all sentiment classes.\n",
        "\n",
        "**Automated Data Labeling:**\n",
        "*   Utilizing PCA and KMeans clustering for automated data labeling proved to be a valuable technique for exploratory analysis and understanding the data distribution.\n",
        "\n",
        "*   Automated data labeling can provide insights into the underlying patterns in the data and assist in feature engineering for improving classifier performance.\n",
        "\n",
        "**Future Directions:**\n",
        "*   Further experimentation with advanced feature engineering techniques, such as word embeddings or deep learning models, could potentially improve sentiment classification accuracy.\n",
        "\n",
        "*   Exploring ensemble learning methods or model stacking techniques may enhance overall model performance by combining the strengths of multiple classifiers.\n",
        "\n",
        "*   Continuous monitoring and updating of the sentiment analysis model with new data can ensure its relevance and effectiveness over time.\n",
        "\n",
        "**Limitations:**\n",
        "*   The analysis focused primarily on traditional machine learning classifiers, and incorporating more advanced techniques could lead to further improvements.\n",
        "\n",
        "*   The evaluation metrics used may not fully capture the nuances of sentiment analysis, and exploring additional metrics or domain-specific evaluation approaches could provide deeper insights.\n",
        "\n",
        "\n",
        "In conclusion, the sentiment analysis project highlights the effectiveness of logistic regression and naive Bayes classifiers for sentiment classification tasks. Additionally, the use of automated data labeling techniques such as PCA and KMeans clustering can aid in exploratory analysis and improve understanding of the underlying data distribution. Moving forward, further experimentation with advanced techniques and continuous model refinement are essential for enhancing sentiment analysis accuracy and applicability in real-world scenarios."
      ],
      "metadata": {
        "id": "tBvsrrQf1W87"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}